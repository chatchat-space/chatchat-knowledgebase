#### 行动决策与环境感知的任务协同分析-第二篇

​	上篇在讨论强化学习与agent，指出强化学习虽然在表面上似乎需要专业知识，但实际上牵涉到日常生活中的人类行为逻辑。 

那么对于*Agent是不是替换监督学习和强化学习的方法*的视角，我们抛出几个前置问题

> 机器代理的风险感知与决策与强化学习有什么区别
>
> 新视角否在实际应用中能够提供更好的结果？

看似新的视角，改变了传统强化学习方法，将重点放在价值分布上，并为机器代理的风险感知行为提供了理论基础。这对于改善强化学习算法的性能以及将其应用于更广泛的领域具有潜在的影响。

PS:讨论这个问题其实很可笑,但是碗里没料了~~~

![image-20230909103849920](./imgs/%E8%A1%8C%E5%8A%A8%E5%86%B3%E7%AD%96%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%84%9F%E7%9F%A5%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%8D%8F%E5%90%8C%E5%88%86%E6%9E%90-%E7%AC%AC%E4%BA%8C%E7%AF%87/image-20230909103849920.png)

（一个统一的封面图）



要掌握对着几个问题的讨论尺度，我们需要站在专业的视角谈论一个问题，“模型如何评估“、“度量标准如何评价”，以下内容摘自周志华《西瓜书》中的一部分内容

从训练模型开始，一个模型的经验错误（事实错误）与过拟合（逻辑错误）往往是在模型初期，整理训练参数的时候决定的，我们实际希望的，是在新样本上能表现的很好的学习器，为了达到这个目的，应该 从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”。任何偏于此期望的情况，两极分化出来了两个概念，“欠拟合”与“过拟合”

机器学习面临的问题通常是NP问题，*距离的定义与计算*，而一个有效的学习算法必然是在多项式时间内运行完成。通常，在有效的结构内，寻求一种“经验结果”满足模型的任务，常见的经验函数如KNN\1NN等一些临近算法，临近算法目的是为了使样本映射至高维“特征空间”，在空间维度上实施线性变换或非线性变换，好勒说这么多，挺枯燥的。

那么回去看上面的问题，是不是有了一个不同的角度，即：强化学习与监督学习实际只是，经验函数和空间计算函数（激活函数）不同

至于如何不同呢，我们来水一水。

![image-20231021205743582](./imgs/%E8%A1%8C%E5%8A%A8%E5%86%B3%E7%AD%96%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%84%9F%E7%9F%A5%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%8D%8F%E5%90%8C%E5%88%86%E6%9E%90-%E7%AC%AC%E4%BA%8C%E7%AF%87/image-20231021205743582.png)

（一个关于做了很牛逼事情的沙雕图）

从我们（小学二年级）的课本中介绍，临近算法是一种监督学习算法，常用于数据挖掘、目标匹配等任务中，强化学习算法是一类用于训练智能体在与环境互动中学习最佳决策策略的算法，这里其实已经点出了，如果想让监督学习的任务更加准确，必然需要设计一个强化学习的策略来满足任务（老生常谈的问题了）



#### 低维嵌入

现实应用中，我们已经有了一个LLM(自然语言大模型)，当然这个模型肯定是有偏好的，上面已经解释了原因，这里不做赘述。当我们再用大模型的时候都会遇到一个问题，它好像对我说的概念不知道，例如，“苹果掉下来”这个句话，放在牛顿那里就是万有引力，放在小猪面前,就是把你吃掉。结果显而易见，模型需要一个调参，或者说模型需要一个空间维度的提示。

![images](./imgs/%E8%A1%8C%E5%8A%A8%E5%86%B3%E7%AD%96%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%84%9F%E7%9F%A5%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%8D%8F%E5%90%8C%E5%88%86%E6%9E%90-%E7%AC%AC%E4%BA%8C%E7%AF%87/images.jpeg)

回到课堂上，来讨论问题，假定属性维数为20，若要求样本未满足密采样条件，则至少需 $ (x10^3)^{20} = 10^{60} $个样本，现实应用中属性维数经常成千上万，要满足密采样条件所需的样本数目是无法达到的天文数字，事实上，在高维情形下出现的数据样本稀疏，距离计算困难等问题，是所有机器学习方法共同面临的严重障碍，被称为“维数灾难”，这种问题可以在降维，即低维空间中得到解决。

这个问题确实有点难以理解，还是一样，先提出几个问题，什么是高维度空间，什么是低维空间，什么是空间映射，空间映射是如何发生的

打开没读过的课本，在看上我们讨论过维度这个名词，我们有好几种解释、空间维度、数据维度、向量空间维度等等，

![image-20231021213107635](./imgs/%E8%A1%8C%E5%8A%A8%E5%86%B3%E7%AD%96%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%84%9F%E7%9F%A5%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%8D%8F%E5%90%8C%E5%88%86%E6%9E%90-%E7%AC%AC%E4%BA%8C%E7%AF%87/image-20231021213107635.png)

（此处是一个高维空间在同空间下，低维的子空间映射图）

图中是一个空间坐标与相机坐标的变换公式，当前这个公式，不一定大家都看过，解释起来也挺困难的，桀桀桀，大家自己去看看吧~

我们来说下，为什么用这个公式举例，试想一下，如果不存在这个公式，那如何存储一个空间转换的位置关系（原点坐标与世界坐标的关系），一个位置发生了变化之后，元坐标与法线的关系，如果使用矩阵存储，必然会占用大量的空间，在尝试坐标计算时，计算量是无法估计的情况，引入上方的公式，就好像找到了一个无形的变换关系，结果自然会在 `投影点`出现

![image-20231021221344238](./imgs/%E8%A1%8C%E5%8A%A8%E5%86%B3%E7%AD%96%E4%B8%8E%E7%8E%AF%E5%A2%83%E6%84%9F%E7%9F%A5%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%8D%8F%E5%90%8C%E5%88%86%E6%9E%90-%E7%AC%AC%E4%BA%8C%E7%AF%87/image-20231021221344238.png)

回到LLM的问题，如何给模型一个空间维度的提示（投影坐标的关系），回到聚类问题，尝试给文本增加语义解释之后，这个聚类分组就有了

上面的例子是线性维度下的直观距离，但是很多时候，模型处理的任务都是非线性的
